{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX_0dMB60t6S",
        "outputId": "233c07b1-de28-42c4-bd27-ae4125eb09d3"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'serpapi'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflask\u001b[39;00m \u001b[39mimport\u001b[39;00m Flask, request, jsonify\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mserpapi\u001b[39;00m \u001b[39mimport\u001b[39;00m GoogleSearch\n\u001b[0;32m      3\u001b[0m \u001b[39m#from pyngrok import ngrok\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'serpapi'"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from serpapi import GoogleSearch\n",
        "#from pyngrok import ngrok\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "app = Flask(__name__)\n",
        "model = tf.keras.models.load_model('best_model.h5')\n",
        "class_names = ['Accessory Gift Set', 'Baby Dolls', 'Backpacks', 'Bangle', 'Basketballs', 'Bath Robe', 'Beauty Accessory', 'Belts', 'Blazers', 'Body Lotion', 'Body Wash and Scrub', 'Booties', 'Boxers', 'Bra', 'Bracelet', 'Briefs', 'Camisoles', 'Capris', 'Caps', 'Casual Shoes', 'Churidar', 'Clothing Set', 'Clutches', 'Compact', 'Concealer', 'Cufflinks', 'Cushion Covers', 'Deodorant', 'Dresses', 'Duffel Bag', 'Dupatta', 'Earrings', 'Eye Cream', 'Eyeshadow', 'Face Moisturisers', 'Face Scrub and Exfoliator', 'Face Serum and Gel', 'Face Wash and Cleanser', 'Flats', 'Flip Flops', 'Footballs', 'Formal Shoes', 'Foundation and Primer', 'Fragrance Gift Set', 'Free Gifts', 'Gloves', 'Hair Accessory', 'Hair Colour', 'Handbags', 'Hat', 'Headband', 'Heels', 'Highlighter and Blush', 'Innerwear Vests', 'Ipad', 'Jackets', 'Jeans', 'Jeggings', 'Jewellery Set', 'Jumpsuit', 'Kajal and Eyeliner', 'Key chain', 'Kurta Sets', 'Kurtas', 'Kurtis', 'Laptop Bag', 'Leggings', 'Lehenga Choli', 'Lip Care', 'Lip Gloss', 'Lip Liner', 'Lip Plumper', 'Lipstick', 'Lounge Pants', 'Lounge Shorts', 'Lounge Tshirts', 'Makeup Remover', 'Mascara', 'Mask and Peel', 'Mens Grooming Kit', 'Messenger Bag', 'Mobile Pouch', 'Mufflers', 'Nail Essentials', 'Nail Polish', 'Necklace and Chains', 'Nehru Jackets', 'Night suits', 'Nightdress', 'Patiala', 'Pendant', 'Perfume and Body Mist', 'Rain Jacket', 'Rain Trousers', 'Ring', 'Robe', 'Rompers', 'Rucksacks', 'Salwar', 'Salwar and Dupatta', 'Sandals', 'Sarees', 'Scarves', 'Shapewear', 'Shirts', 'Shoe Accessories', 'Shoe Laces', 'Shorts', 'Shrug', 'Skirts', 'Socks', 'Sports Sandals', 'Sports Shoes', 'Stockings', 'Stoles', 'Sunglasses', 'Sunscreen', 'Suspenders', 'Sweaters', 'Sweatshirts', 'Swimwear', 'Tablet Sleeve', 'Ties', 'Ties and Cufflinks', 'Tights', 'Toner', 'Tops', 'Track Pants', 'Tracksuits', 'Travel Accessory', 'Trolley Bag', 'Trousers', 'Trunk', 'Tshirts', 'Tunics', 'Umbrellas', 'Waist Pouch', 'Waistcoat', 'Wallets', 'Watches', 'Water Bottle', 'Wristbands']\n",
        "  # List of class names\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    if 'image' not in request.files:\n",
        "        return jsonify({'error': 'No image provided'}), 400\n",
        "\n",
        "    image = request.files['image']\n",
        "    img_bytes = image.read()\n",
        "\n",
        "\n",
        "    img = tf.image.decode_png(img_bytes, channels=3)\n",
        "    img = tf.image.resize(img, (224, 224))\n",
        "    img = np.expand_dims(img/255, axis=0)\n",
        "\n",
        "    predictions = model.predict(img)\n",
        "    predicted_class = class_names[np.argmax(predictions)]\n",
        "\n",
        "\n",
        "\n",
        "    q=predicted_class\n",
        "\n",
        "    params = {\n",
        "      \"q\": q,  \t# search query\n",
        "      \"tbm\": \"shop\",  # shop results\n",
        "      \"num\": 12,\n",
        "      \"gl\": \"uk\",\n",
        "      \"hl\": \"en\",\n",
        "      \"device\":\"mobile\",\n",
        "      \"engine\":\"google_shopping\",\n",
        "      \"api_key\": \"657fe8cc427776105c2828f44e05c1a918bdd6d02bf4881a3457644ed77995a9\"\n",
        "\n",
        "    }\n",
        "\n",
        "    search = GoogleSearch(params)\n",
        "\n",
        "    results = search.get_dict()\n",
        "\n",
        "\n",
        "    extracted_results = []\n",
        "\n",
        "    for item in results[\"shopping_results\"]:\n",
        "        extracted_item = {\n",
        "\n",
        "            \"link\": item.get(\"link\", \"\"),\n",
        "            \"title\": item.get(\"title\", \"\"),\n",
        "            \"price\": item.get(\"price\", \"\")\n",
        "        }\n",
        "        extracted_results.append(extracted_item)\n",
        "\n",
        "    # Printing the extracted results\n",
        "    for extracted_item in extracted_results:\n",
        "        #print(\"Thumbnail:\", extracted_item[\"thumbnail\"])\n",
        "        print(\"Link:\", extracted_item[\"link\"])\n",
        "        print(\"Title:\", extracted_item[\"title\"])\n",
        "        print(\"Price:\", extracted_item[\"price\"])\n",
        "        print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "       # Create a dictionary containing both pieces of information\n",
        "    response_data = {\n",
        "        \"predicted_class\": predicted_class,\n",
        "        \"extracted_results\": extracted_results\n",
        "    }\n",
        "\n",
        "\n",
        "    return jsonify(response_data)\n",
        "\n",
        "\n",
        "\n",
        "public_url = ngrok.connect(addr='5000')\n",
        "print('Public URL:', public_url)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=5000)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement google-search-python (from versions: none)\n",
            "ERROR: No matching distribution found for google-search-python\n"
          ]
        }
      ],
      "source": [
        "!pip install google-search-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'keras' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Load the saved model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(\u001b[39m\"\u001b[39m\u001b[39mbest_model.h5\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Assuming you have a validation generator defined, use it for evaluation\u001b[39;00m\n\u001b[0;32m      5\u001b[0m validation_loss, validation_accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(validation_generator)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ],
      "source": [
        "# Load the saved model\n",
        "model = keras.models.load_model(\"best_model.h5\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement serpapi (from versions: none)\n",
            "ERROR: No matching distribution found for serpapi\n"
          ]
        }
      ],
      "source": [
        "!pip install serpapi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVd5whaJzeOw"
      },
      "outputs": [],
      "source": [
        "public_url = ngrok.connect(port=8000)\n",
        "print(\"Public URL:\", public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGR3sY_0p-8_",
        "outputId": "31dd74eb-a8fe-413a-eea1-24d15645282c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-6.0.0.tar.gz (681 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m681.2/681.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-6.0.0-py3-none-any.whl size=19867 sha256=50b8521140ad9b243fa3b3e654a84ea7acf92293210e57fbdfe6377513c589c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/42/78/0c3d438d7f5730451a25f7ac6cbf4391759d22a67576ed7c2c\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXC8pfr4E6dL",
        "outputId": "57581ffe-2082-466d-dc6c-c9c78f381234"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2023.7.22)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32003 sha256=44187ff7c75a5beb8884fdb801bf376570545260022c69d0a559eeb866dd2b21\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ],
      "source": [
        "pip install google-search-results\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
